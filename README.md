Hoofdstuk 1 Kunstmatige Intelligentie

Kunstmatige intelligentie is een paraplubegrip waaronder de machines vallen die menselijke handelingen nabootsen om problemen op te lossen, beslissingen nemen en het uitvoeren van bepaalde taken. Er vallen dus verscheidende zaken onder het begrip ‘AI’. Voorbeelden hiervan zijn: Een Tesla met automatische modus, het aanbevelingssysteem van Netflix en Chat-GPT. De vijf belangrijkste taken van kunstmatige intelligentie zijn leren, redenering, probleemoplossing, perceptie en het begrijpen van talen.
De belangrijkste functie van kunstmatige intelligentie is het leren van nieuwe dingen. Het leerproces bestaat uit het uitbreiden van de kennis (data) en het onthouden daarvan. Zo kan een systeem de data gebruiken voor het oplossen van verschillende problemen. Niet alleen het leren van nieuwe dingen is belangrijk; Redenering is ook cruciaal voor het maken van correcte conclusies. Redenering is de kunst om argumenten of beweringen te gebruiken die leiden tot een conclusie. Heel lang kon alleen het menselijk brein dit maar met de opkomst van de technologische ontwikkelingen heeft software ervoor gezorgd dat kunstmatige intelligentie dit ook kan. Het derde belangrijke component is het oplossen van problemen. Dit doet kunstmatige intelligentie doormiddel van het toepassen en veranderen van data. Kunstmatige intelligentie kan ook zorgen voor het ontwikkelen van efficiënte algoritmes en het uitvoeren van een oorzaak analyse met het doel om een oplossing te vinden. Deze oplossingen hebben veel data nodig. Deze data moet ergens vandaan komen daarom is perceptie van kunstmatige intelligentie onmisbaar. Dit kan gerealiseerd worden doormiddel van verschillende sensoren die informatie van de buitenwereld vergaren. Zo moet kunstmatige intelligentie wel snappen wat er bijvoorbeeld gezegd wordt. Doordat de meeste AI programma’s in het Engels zijn ontwikkeld, begrijpt het programma ook de Engelse taal. Dit zorgt ervoor dat er gecommuniceerd kan worden met de kunstmatige intelligentie. Hierdoor kan de gebruiker aangeven wat het probleem is. Met deze input kan kunstmatige intelligentie proberen het probleem op te lossen en hiervan te leren. De mens blijft daarom een cruciale rol spelen in het selecteren van problemen en het bijsturen van kunstmatige intelligentie (CaseGuard, 2022).![image](https://github.com/MrSwitcher/Demityfing_AI_Repository/assets/150449955/545a0c43-c9a6-437f-8d9e-ee0ae79a9458)


Hoofdstuk 2 ChatGPT
Afgelopen jaar is de populariteit van ChatGPT onwijs gestegen. ChatGPT is een chatbot die gebaseerd is op kunstmatige intelligentie om op complexe vragen antwoord te geven. Dit doet ChatGPT op een ‘menselijke manier’ doordat het een groot arsenaal aan data heeft.
Het probleem dat ChatGPT oplost is het efficiënter maken van basis taken. Hetgeen waar ChatGPT bekwaam over is: Het beantwoorden van vragen, het geven van informatie over verschillende onderwerpen, het genereren van ‘menselijke’ teksten, het vertalen van teksten, teksten samenvatten, suggesties geven, helpen met programmeren en het voeren van interactieve en dynamische conversaties. Kort samengevat, het genereren en begrijpen van ‘menselijke’ taal. ChatGPT kan daarom op verschillende vlakken worden ingezet. Een paar voorbeelden hiervan zijn: content maken, educatie, vertaling, informatie opvragen, creatief schrijven, het genereren van code en chatbots. Het kan dus voor verschillende taken ingezet worden, waar het begrijpen van een taal en het genereren ervan essentieel is.
De userinterface van ChatGPT bestaat uit een tekst-invoerveld, chatvenster, verscheidende knoppen voor bijvoorbeeld: de instellingen, het versturen van het bericht, het delen van de chat, het opnieuw generen van de output, etc. ChatGPT heeft aan de linkerzijde een balk met daarin de geschiedenis van de gestelde vragen.
Het AI-model dat de gratis versie van ChatGPT momenteel gebruikt is GPT-3.5. Voorheen was dit GPT-3. Dit is de derde generatie van de generatieve vooraf-getrainde transformer; een groot taal model. De premium versie van Chat-GPT gebruikt het GPT-4 model. GPT-4 kan veel complexere taken oplossen en heeft tevens een snellere reactie tijd. Het algoritme waar ChatGPT mee leert is een subset van ‘machine learning’. Dit wordt ook wel ‘unsupervised learning’ genoemd. De transformator voorspelt de tekst op basis van de trainingsgegevens. De trainingsgegevens bestaan uit grote hoeveelheden tekst. Hierdoor leert het model patronen en structuren van verschillende teksten kennen (Hetler, 2023).


Hoofdstuk 3 Use-cases
Er zijn verscheidende use-cases waarvoor je Chat-GPT zou kunnen gebruiken. Hieronder volgen de belangrijkste use-cases met een korte uitleg van het onderliggende systeem.
- Het maken van content: Chat-GPT kan voor verschillende zaken worden ingezet bij het maken van content. Zo kan Chat-GPT: descripties maken voor producten, posts voor verschillende social media genereren, artikelen schrijven, etc. De prompts voor contentcreatie moeten open en richtinggevend zijn. Dit heeft invloed op het onderwerp, de stijl of de toon van de content. Nadat Chat-GPT de content heeft gecreëerd moet dit te herzien zijn voor de gebruiker zodat dit, indien noodzakelijk, nog aangepast kan worden. Het prestatieniveau moet worden afgestemd op de creatietaken van ChatGPT. Dit kan worden beoordeelt door bijvoorbeeld redacteuren. Om te voorkomen dat er geen plagiaat wordt gepleegd, en dat er goede kwaliteit wordt afgeleverd, moet dit opgenomen worden in de parameters (Dilmegani, 2023).
- Het vertalen van teksten: Chat-GPT kan ook gebruikt worden voor vertaal services. De chatbot heeft namelijk data over bijna alle talen van de wereld. Het is belangrijk voor de prompt dat er duidelijk wordt gemaakt wat de brontaal en doeltaal zijn. Optioneel zou ook nog zijn om het documenttype of de gewenste vertaalstijl toe te voegen aan de prompt. Er moet ook ruimte zijn voor de optie om de vertaalde tekst te beoordelen, bewerken en feedback te kunnen geven voor de gebruiker. Het prestatieniveau van het model zijn nauwkeurigheid, dat de tekst ‘vloeiend loopt’ en consistentie. Voor de parameters geldt dat er gericht wordt op vertaaltaken doormiddel van fine-tuning (Dilmegani, 2023).
- Het schrijven van code: Naast ‘normale’ talen begrijpt Chat-GPT ook codeer taal. Daarmee kan de chatbot helpen met het genereren van code. Het is van belang dat de prompts het programmeerprobleem snappen. Eventueel zouden de programmeertaal en stijl kunnen worden vernoemd. Chat-GPT moet over code-uitvoering en debugtools beschikken voor de ontwikkelaar. Het presentatieniveau moet functionele code genereren met minimale fouten die afstemmen op de rest van de code (indien dat al geschreven is). Voor de parameters geldt dat deze afgestemd zijn op de codegeneratie, debugging en de naleving van de coderingsnormen (Dilmegani, 2023).
- Fact-checking: er zijn online geen voorbeelden van bedrijven die Chat-GPT gebruiken voor fact-checking. Dit komt doordat Chat-GPT niet altijd het goede antwoord geeft want het gratis datamodel heeft kennis tot september 2021. De prompts die bij Fact-checking belangrijk zijn is: dat de bewering of verklaring gespecificeerd wordt, en natuurlijk ook gecheckt. Hierbij is context bij de bewering/verklaring erg belangrijk. Het is van belang dat er ook bronnen worden vermeld bij de informatie zodat die door de gebruiker geverifieerd kan worden. Voor de parameters geldt om toegang tot een betrouwbare uitgebreide database met informatiebronnen te hebben (Abels, 2023).
- Beantwoorden van vragen: Microsoft maakt gebruik van Chat-GPT voor het beantwoorden van vragen. Dit doet Microsoft doormiddel van de zoekmachine Bing. De prompt moet de vraag bevatten met eventuele context of documentbronnen die relevant zijn. Chat-GPT moet de gebruiker in staat stellen om de vraag te verfijnen, of om aanvullende informatie te geven voor de vraag. Het antwoord dat gegeven wordt moet relevant zijn en natuurlijk kloppen. Wat betreft parameters, moet er een vraag-antwoord dataset zijn, en het aanpassen van parameters voor zoeken en ophalen. (Marr, 2023)
- Les geven: Khan lab school gebruikt Chat-GPT voor het geven van les. De prompt moet het educatieve onderwerp/vraag bevatten. Het is ook belangrijk om het aan te vullen met het niveau van de student en het leerdoel. Uiteindelijk moet Chat-GPT een persoonlijke leerstijl ontwikkelen voor de gebruiker. Het is ook belangrijk dat er per onderwerp/vraag uitleg geboden wordt en dat het zich aanpast aan de vooruitgang van de gebruiker. De parameters die gebruikt moeten worden zijn: educatieve content en verschillende leermodellen (Smith, 2023). 
- ‘Theory of mind’ probleemoplossing: het is ChatGPT nog niet gelukt om vlekkeloos alle Theorie of mind problemen op te lossen: “Large language models (LLMs) excel in many tasks in 2023, but they still face challenges in complex reasoning. Theory-of-mind (ToM) tasks, which require understanding agents' beliefs, goals, and mental states, are essential for common-sense reasoning involving humans, making it crucial to enhance LLM performance in this area” (Moghaddam & Honey, 2023). De prompt moet bestaan uit een scenario of probleem dat begrip en redenering bevat over bepaalde normen en waarden. De gebruiker moet dan verschillende standpunten verkrijgen en een mogelijke oplossing. Het is belangrijk dat Chat-GPT neutraal blijft en niet een standpunt inneemt. Voor de parameters is een training van een dataset over redernering belangrijk.
- APA citatie: Er zijn veel scholieren die Chat-GPT gebruiken voor de APA citatie. Belangrijk is dat de prompt de informatie bron bevat en dat de APA-stijl moet worden toegepast. Dan moeten vervolgens citatievoorstellen en opmaakondersteuning worden aangeboden aan de gebruiker. De citaten moeten foutloos zijn. De parameters hiervoor zijn: de citatiegeneratie en naleving van stijlgidsen.


Hoofdstuk 4 Drie review artikelen
De onderstaande artikelen zijn uitgekozen omdat deze artikelen relevant zijn en laten zien dat het niet altijd de beste oplossing is om kunstmatige intelligentie te gebruiken. Met deze drie artikelen kan men zeggen dat onder strak toezicht er niks fout kan gaan met kunstmatige intelligentie. 
Het nadeel van Large Language Models, zoals Chat-GPT, is dat de gebruiker gemakzuchtig wordt. Dit gaat ten koste van de intellectuele en creatieve inspanning. Dit staat in strijd met de menselijke vermogens en de productiviteit. De technologieën verleidt de gebruiker om een gemakkelijke en snelle oplossing te verkrijgen, zonder dat er enig uitdaging en een worsteling is van de menselijke inspanning. Een ander punt is dat het vertrouwen in informatie in gevaar kan komen omdat deze modellen verantwoordelijke en betrouwbare menselijke communicatie ondermijnen. Dit betekend dat de emotionele waarde van woorden verloren gaat omdat LLM’s dit niet kunnen ‘aanvoelen’.
Het is daarom belangrijk om op een verstandig manier met kunstmatige intelligentie om te gaan. Dit kan gedaan worden door vast te houden aan productieve inspanningen en menselijke waarden. Hiervoor heeft de gebruiker wel discipline nodig om niet altijd voor de makkelijke technologische uitweg te gaan. Zo blijft de menselijkheid in de wereld die steeds meer wordt geautomatiseerd door machines (Bilbro, 2023).
De G7-landen zijn ook druk bezig op het gebied van kunstmatige intelligentie, zodat AI veilig en betrouwbaar blijft. Pas hebben de G7-landen een gedragscode opgesteld voor bedrijven. Dit bestaat uit elf punten en rapportage over mogelijkheden, beperkingen, beveiligingscontroles en het voorkomen van misbruik.
Experts waarschuwen voor de risico’s van AI, zoals foutieve informatie, discriminatie en polarisatie. Doordat de ontwikkelingen in een rap tempo gaan, is er bezorgdheid ontstaan dat de controle verloren kan gaan. De Europese Unie heeft al wel regels voor AI, In tegenstelling tot Japan en de Verenigde Staten (Wijkman, 2023).
Nu is het natuurlijk niet de bedoeling dat er een mate van angst ontstaat om kunstmatige intelligentie te gebruiken. Dit beeld wordt voorgeschoteld door de media. Denk bijvoorbeeld aan de Terminator die heel de wereld overneemt. Dit scenario is onwaarschijnlijk doordat de regelgeving dit niet toelaat. AI-systemen zijn weliswaar zeer intelligent, echter hebben deze systemen geen bewustzijn of begrip. Dit betekend dat er geen eigen wil aan te pas komt om actie te ondernemen.
De echte zorg ligt in het gebruik van kunstmatige intelligentie bij kritische beslissingen, zoals social media of financiële zaken. Het is daarom van belang om dit te controleren zodat er geen schadelijke gevolgen ontstaan. Dit kan voorkomen worden door goed geïnformeerd te zijn over kunstmatige intelligentie en de maatschappelijke impact, in plaats van op het gevoel te handelen zonder enig achtergrondinformatie te hebben (Bakker, 2023).

 
Reflectie
De afgelopen tien jaar zijn er verscheidende ontwikkelen geweest op het gebied van kunstmatige intelligentie. De ene ontwikkeling nog populairder dan de ander. De belangrijkste ontwikkelen die geboekt zijn: taalverwerking, beeldverwerking, robotica, gezondheid en financiën. Hieronder worden de onderwerpen verder toegelicht.
Op basis van de taalverwerking zijn de netwerktaal modellen ELMo, GPT, mT5 en BERT ontwikkeld. Deze modellen kunnen op basis van menselijke input reageren. Dit kan gebruikt worden voor vertaling, tekstclassificatie, spraakherkenning en chatbots. Dit was in het verleden nog niet mogelijk, of op zo een laag niveau dat het model nog veel input nodig had van buitenaf. Wat nog meer niet mogelijk was, is het genereren van fotorealistische afbeeldingen en video’s binnen de beeldverwerking. Beeld kon alleen worden vastgesteld met een camera. Door de komst van kunstmatige intelligentie kunnen camera’s nu ook gezichten, en objecten herkennen. Tevens wordt dit gebruikt in de robotica. Denk bijvoorbeeld aan zelfrijdende auto’s en robots. Doormiddel van sensoren en machine learning kunnen basis handelingen worden uitgevoerd in bijvoorbeeld fabrieken. Dit heeft ervoor gezorgd dat werknemers ontslagen/omgeschoold werden. Gelukkig is dit niet het geval geweest in de zorg. Kunstmatige intelligentie heeft wel het werk makkelijker gemaakt voor doctoren door toepassingen in diagnoses, medicijnontdekkingen, gezondheidsvoorspellingen en medisch beeldgebruik. Als laatst heeft kunstmatige intelligentie ook een doorslag gegeven in financiële instellingen. Dit kan men vooral terugzien in leningsbeslissingen, fraudeopsporing en automatiseringen van adviesdiensten. Het wordt ook gebruikt voor risicoschatting en hoge frequentie verhandelingen. (Stanford University, 2021)
Het probleem dat kunstmatige intelligentie verbeterd is: de efficiëntie bevorderen van basis handelingen. De ontwikkelingen zorgen ervoor dat er steeds complexere taken en vraagstukken kunnen worden opgelost. Dit kan worden geconstateerd in het dagelijks leven. Denk bijvoorbeeld aan de scholier die ChatGPT gebruikt voor zijn huiswerk, de chatbots die helpen bij verschillende vragen, de camera die het gezicht herkend en automatisch de deur opent, de robot ober bij Shabu Shabu, etc. Het is dus wel degelijk bewezen dat kunstmatige intelligentie het leven efficiënter maakt zodat de mens zich kan richten op meer complexere taken. Echter is niet alles zonder kleerscheuren. De AI-wet is onderverdeelt in vier groepen potentiële risico’s. Dit zijn onaanvaardbaar, hoog risico, beperkt risico en minimaal risico. Onder de categorie onaanvaardbaar valt subliminale technieken, uitbuitende systemen, realtime biometrische identificatiesystemen op afstand of door overheidsinstanties gebruikte sociale scoresystemen. Deze systemen zijn ten strengste verboden. Onder hoog risico vallen toepassingen op het gebied van vervoer, onderwijs, werkgelegenheid en welzijn. Als een AI-systeem hiermee te maken heeft dan moet het aan een lange lijst vereisten voldoen voor de veiligheid. Ook moet de database openbaar toegankelijk zijn om transparantie uit te stralen. Bij het beperkt risico hoeft een AI-systeem alleen te voldoen aan specifieke transparantieverplichtingen. Een voorbeeld hiervan is: dat een chatbot de gebruiker moet informeren dat er met een machine wordt gepraat. Het laagste risico is het minimale risico. Deze systemen worden op grote schaal ingezet. Dit zijn bijvoorbeeld spamfilters, AI games en voorraadbeheersysteem. (FTI Consulting, 2023)


Bronnenlijst
CaseGuard. (2022, 18 maart). The Five Basic Components of AI New Software Development. Caseguard. Geraadpleegd van https://caseguard.com/articles/the-five-basic-components-of-ai-new-software-development/
Hetler, A. (2023, 1 oktober). ChatGPT Definition - What is generative AI? Techtarget. Geraadpleegd van https://www.techtarget.com/whatis/definition/ChatGPT#:~:text=What%20is%20generative%20AI%3F,Everything%20you%20need%20to%20know&text=ChatGPT%20now%20uses%20the%20GPT,response%20time%20and%20internet%20plugins/
Dilmegani, C. (2023, 1 oktober). 50 ChatGPT Use Cases in 2023. AImultiple. Geraadpleegd van https://research.aimultiple.com/chatgpt-use-cases/
Abels, G. (2023, 31 mei). Will ChatGPT AI Replace Fact-Checking? Poynter. Geraadpleegd van https://www.poynter.org/fact-checking/2023/chatgpt-ai-replace-fact-checking/
Marr, B. (2023, 30 mei). 10 Amazing Real-World Examples of How Companies Are Using ChatGPT in 2023. Forbes. Geraadpleegd van https://www.forbes.com/sites/bernardmarr/2023/05/30/10-amazing-real-world-examples-of-how-companies-are-using-chatgpt-in-2023/?sh=69df1e731441
Smith, J. (2023, 3 april). Khanmigo, a ChatGPT Tutor, Is the Next Big Thing in Silicon Valley. The Washington Post. Geraadpleegd van https://www.washingtonpost.com/technology/2023/04/03/chatgpt-khanmigo-tutor-silicon-valley/
Moghaddam, S. & Honey J. (2023, april 22). Boosting Theory-of-Mind Performance in Large Language Models via Prompting. arXiv. Geraadpleegd van https://arxiv.org/abs/2304.11490
Bilbro, J. (2023, 7 juli). What Problem Does ChatGPT Solve? Plough. Geraadpleegd van https://www.plough.com/nl/topics/life/technology/what-problem-does-chatgpt-solve
Wijkman, T. (2023, 30 oktober). G7 publiceert gedragscode om kunstmatige intelligentie veilig te houden. NU.nl. Geraadpleegd van https://www.nu.nl/tech/6287513/g7-publiceert-gedragscode-om-kunstmatige-intelligentie-veilig-te-houden.html
Bakker, S. (2023, 31 augustus). Beeld van AI vaak verkeerd. NEMO Kennislink. Geraadpleegd van https://www.nemokennislink.nl/publicaties/beeld-van-ai-vaak-verkeerd/
Stanford University. (2021). What are the most important advances in AI? Stanford University. Geraadpleegd van https://ai100.stanford.edu/gathering-strength-gathering-storms-one-hundred-year-study-artificial-intelligence-ai100-2021-1/sq2
FTI Consulting. (2023, 25 juli). Four Risks in the EU's Artificial Intelligence Act. FTI Journal. Geraadpleegd van https://www.fticonsulting.com/insights/fti-journal/four-risks-eus-artificial-intelligence-act#:~:text=Unacceptable%3A%20Applications%20that%20comprise#discreet%20influence
